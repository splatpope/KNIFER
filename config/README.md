# KNIFER Config files

Configuration files used by KNIFER are JSON files representing a python dict()
which describes a GAN architecture.

## Hyperparameters

In order to describe an architecture, you need to define the following hyperparameters
in the configuration file (their expected type is between parenthesis) :

- *arch* (str): GAN architecture you want to use. Valid names are in *training/manager.py* in the *KNIFER_ARCHS* dictionnary. For convenience, empty folders with those valid names are present in this directory, so that you may better organize your config files.

- *img_size* (int): Size of the images you want to treat. This describes both the image sizes of your training dataset and the images generated by the GAN. Ideally, keep that value to powers of 2.

- *features_g* (list): List of input features (kernels) for each convolutional layer of the generator model.

- *features_d* (list): List of input features (kernels) for each convolutional layer of the discriminator model.

- *upscales* (list): List of upscaling factors for each convolutional layer of the generator (excluding the first, which always expands the input latent vector to 4x4 matrices)

- *downscales* (list): List of downscaling factors for each convolutional layer of the discriminator (excluding the last, which always reduces its input 4x4 matrices to a scalar)

For obvious reasons, the scaling and feature lists should be the same size for the same model. 

Input features for the first layers are always equal to the latent space size for the generator, and the image channels for the discriminator, so the first layer is not defined by these lists, meaning that **the number of layers is equal to the size of the lists minus 1**.

As a practical design rule, the discriminator should have increasing features ("stretching up" the image) and the generator should have decreasing features ("squashing down" the image).

Example : DCGAN architecture with 128 base features doubling the first three steps, building images of size 256 in 5 layers : 

    {
        "arch": "DCGAN",
        "img_size": 256,
        "features_d": [128, 256, 512, 512]
        "features_g": [512, 512, 256, 128],
        "upscales": [4, 4, 2, 2],
        "downscales": [2, 2, 4, 4],
    }

As you can see, the number of layers for each model is indirectly decided from the image size and scaling lists.

## Automatic architecture building

You may let the training manager build an architecture for you by replacing the scaling and feature lists by a single parameter named *features*.

This will result in an arch with scaling and feature lists which double at each step, and a number of layers equal to ```log2(img_size) - 1```.

Example : The two following configs are functionally equivalent

    {
        "arch": DCGAN,
        "img_size": 32,
        "features_d": [32, 64, 128],
        "features_g": [128, 64, 32],
        "upscales": [2, 2, 2],
        "downscales": [2, 2, 2],
    }

    {
        "arch": DCGAN,
        "img_size": 32,
        "features": 32,
    }

## Specific hyperparameters

### SAGAN

- *attn_spots* (list): List of indices indicating which middle layers should be followed by a self attention module.

## Organizing your config files

Here is how we suggest you organize your config files :

1. On the top level of this directory, make folders corresponding the every arch (already made for you).

2. In these directories, make folders corresponding to every image size you want to treat.

3. In these directories, put config files whose names summarize the layout of your models
(e.g. "5_1a.json" for models that both have 5 layers and an attention module at the second middle layer, i.e. the third one).

Note that you may use any folder structure you want.
